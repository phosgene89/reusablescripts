{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Keras Generator\n",
    "This notebook outlines how to build custom Keras generators. These are used to feed in more complex data into models with potentially complex processing, such as image augmentation. It also allows for multiple datasets to be fed into the model for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/greg/standard_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow\n",
    "\n",
    "# Load entire dataset\n",
    "X = np.linspace(0,100, 1000)\n",
    "y = np.sin(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return np.reshape(X, (32,1)), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "\n",
    "        # Generate data\n",
    "        for idx in indexes:\n",
    "            # Store sample\n",
    "            X = self.X[indexes]\n",
    "\n",
    "            # Store class\n",
    "            y = self.y[indexes]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 5141.1209\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 3569.2337\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 2436.7188\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1547.8876\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 874.3285\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 412.3970\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 137.3279\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 20.1537\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.8901\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4740b1828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design model\n",
    "model = Sequential()\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit(train_generator, steps_per_epoch = len(X)//32, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Input/Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X,y, batch_size = 64):\n",
    "    \n",
    "    \"\"\"\n",
    "    Overview\n",
    "    --------\n",
    "    Simple Keras data generating function.\n",
    "    \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    X (numpy.ndarray): NumPy array of training data, with number\n",
    "        of samples in the first dimension.\n",
    "    y (numpy.ndarray): NumPy array of target data, with number\n",
    "        of samples in the first dimension.\n",
    "    batch_size (int, optional): Batch size.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Subset of X and y of size batch_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_length = len(X)\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_idx = np.random.randint(0, X_length, (batch_size))\n",
    "        \n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        batch_x = np.array(X[batch_idx])\n",
    "        batch_y = np.array(y[batch_idx])\n",
    "        \n",
    "        yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design model\n",
    "model = Sequential()\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 18.6917\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.5521\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5546\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5482\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5512\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5452\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.5406\n",
      "Epoch 8/10\n",
      " 87/156 [===============>..............] - ETA: 0s - loss: 0.5645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d15a49a3b1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m           update_ops.extend(\n\u001b[1;32m    484\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 485\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/rmsprop.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    185\u001b[0m       var_t = var - coefficients[\"lr_t\"] * grad / (\n\u001b[1;32m    186\u001b[0m           math_ops.sqrt(denom_t) + coefficients[\"epsilon\"])\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resource_apply_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         validate_shape=validate_shape)\n\u001b[0;32m--> 228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    816\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[1;32m    817\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     return _UnreadVariable(\n\u001b[1;32m    789\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m   \u001b[0;34m\"\"\"Records that `variable` was accessed for the tape and FuncGraph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"watch_variable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5875\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m   \"\"\"\n\u001b[0;32m-> 5877\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5456\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5457\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5459\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5271\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(image_generator(X, y, 32), steps_per_epoch = len(X)//64, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 331.6825\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 4s 24ms/step - loss: 67.1280\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 8.0176\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.7204\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.5353\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.5369\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 4s 28ms/step - loss: 0.5189\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 4s 25ms/step - loss: 0.5062\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 4s 24ms/step - loss: 0.5032\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 4s 23ms/step - loss: 0.5097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f439c2d5470>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs_main = Input(shape=(1,))\n",
    "inputs_aux = Input(shape=(1,))\n",
    "\n",
    "output_1_main = Dense(1, activation='relu')(inputs_main)\n",
    "output_2_main = Dense(1, activation='relu')(output_1_main)\n",
    "\n",
    "output_1_aux = Dense(1, activation='relu')(inputs_aux)\n",
    "output_2_aux = Dense(1, activation='relu')(output_1_aux)\n",
    "\n",
    "added = tensorflow.keras.layers.Add()([output_2_main, output_2_aux])\n",
    "\n",
    "predictions = Dense(1)(added)\n",
    "\n",
    "model = Model(inputs=[inputs_main, inputs_aux], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit_generator(multi_input_data_generator(X, y, 32), steps_per_epoch = len(X)//64, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the data is in the format (time step, feature)\n",
    "\n",
    "the data will be in the format (sample, time_step, feature) after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_series_generator:\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates batches of time series data suitable for Keras.\n",
    "    \n",
    "    Keras requires time series data to be fed in with the format \n",
    "    (batch_size, time_lags, features). This generator automatically\n",
    "    reshapes tabular data. It also adds sinusoidal waves to give the\n",
    "    neural net some concepts of where in the period we are located,\n",
    "    as neural networks do not model periodicity very well.\n",
    "    \n",
    "    Handles multivariable inputs and outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, lags, horizon, batch_size, period):\n",
    "        \n",
    "        \"Initialise generator class.\"\n",
    "        \n",
    "        self.lags = lags\n",
    "        self.horizon = horizon\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.period = period\n",
    "        \n",
    "        self.sin_period, self.cos_period = self.calc_sinusoidal_time(self.period)\n",
    "        \n",
    "    def calc_sinusoidal_time(self, period):\n",
    "        \n",
    "        \"\"\"\n",
    "        Encodes periodicity of the data into sinusoidal features.\n",
    "        \n",
    "        \n",
    "        Inputs\n",
    "        ------\n",
    "        period (int): Periodicity of the data.\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A pair of sine and cosine wave with periodicity equal to\n",
    "            the passed value of period.\n",
    "        \"\"\"\n",
    "        \n",
    "        t = np.arange(len(self.X)) % period\n",
    "        wave_arg = 2*np.pi*t/np.max(period)\n",
    "        \n",
    "        return np.sin(wave_arg), np.cos(wave_arg)\n",
    "    \n",
    "    def flow(self, X, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generates a list of input data and target data.\n",
    "        \n",
    "        The input data list contains the reshaped time series data\n",
    "        and another dataset containing sinusoidal features.\n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "        \n",
    "            input_batch_1 = []\n",
    "            sinusoidal_batch = []\n",
    "            targets_batch = []\n",
    "    \n",
    "            for i in range(self.batch_size):\n",
    "                # Need to start indexing from lags\n",
    "                data_idx = np.random.randint(self.lags, len(X) - self.horizon)\n",
    "    \n",
    "                data_lags = X[data_idx - lags: data_idx]\n",
    "                input_batch_1.append(data_lags)\n",
    "            \n",
    "                targets = y[data_idx:data_idx + self.horizon]\n",
    "                targets_batch.append(targets) \n",
    "        \n",
    "                sinusoidal_feature = np.concatenate([self.sin_period[data_idx - self.lags: data_idx], \n",
    "                                                 self.cos_period[data_idx - self.lags: data_idx]])\n",
    "            \n",
    "                sinusoidal_batch.append(sinusoidal_feature)\n",
    "            \n",
    "            input_batch_1 = np.reshape(input_batch_1, (self.batch_size, self.lags, -1))\n",
    "            sinusoidal_batch = np.reshape(sinusoidal_batch, (self.batch_size, self.lags * 2, -1))\n",
    "            targets_batch = np.reshape(targets_batch, (self.batch_size, -1))\n",
    "    \n",
    "            yield [input_batch_1, sinusoidal_batch], targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "lags = 12\n",
    "horizon = 8\n",
    "batch_size =  32\n",
    "period = int(2*np.pi*100)\n",
    "features = 1\n",
    "\n",
    "# Generate data\n",
    "\n",
    "X = np.linspace(0,10,1000).reshape((1000, -1))\n",
    "print(np.shape(X))\n",
    "y = np.sin(X) + np.random.normal(0,0.01, (1000,1))\n",
    "print(np.shape(y))\n",
    "y = y.reshape((1000,1))\n",
    "\n",
    "data_gen = time_series_generator(X, y, lags, horizon, batch_size, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.2752\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0369\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0205\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0129\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0104\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 0.0081\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0059\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0044\n",
      "Epoch 9/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0040\n",
      "Epoch 10/15\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.0031\n",
      "Epoch 11/15\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0028\n",
      "Epoch 12/15\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0023\n",
      "Epoch 13/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0022\n",
      "Epoch 14/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0017\n",
      "Epoch 15/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f424fdb32b0>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "units = 64\n",
    "\n",
    "# This returns a tensor\n",
    "inputs_main = Input(shape=(lags,features))\n",
    "inputs_aux = Input(shape=(lags * 2, 1))\n",
    "\n",
    "output_1_main = Dense(units, activation='relu')(inputs_main)\n",
    "output_2_main = Dense(units, activation='relu')(output_1_main)\n",
    "\n",
    "output_1_aux = Dense(units, activation='relu')(inputs_aux)\n",
    "output_2_aux = Dense(units, activation='relu')(output_1_aux)\n",
    "\n",
    "concat = tensorflow.keras.layers.Concatenate(axis=1)([output_2_main, output_2_aux])\n",
    "\n",
    "flatten = Flatten()(concat)\n",
    "dense1 = Dense(units, activation='relu')(flatten)\n",
    "\n",
    "predictions = Dense(horizon, activation = 'tanh')(dense1)\n",
    "\n",
    "model = Model(inputs=[inputs_main, inputs_aux], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit_generator(data_gen.flow(X, y), steps_per_epoch = len(X)//64, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y.reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_generator(data_gen.flow(X, y), steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0.        ],\n        [0.01001001],\n        [0.02002002],\n        [0.03003003],\n        [0.04004004],\n        [0.05005005],\n        [0.06006006],\n        [0.07007007],\n        [0.08008008],\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-620b435ee574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    529\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0.        ],\n        [0.01001001],\n        [0.02002002],\n        [0.03003003],\n        [0.04004004],\n        [0.05005005],\n        [0.06006006],\n        [0.07007007],\n        [0.08008008],\n ..."
     ]
    }
   ],
   "source": [
    "model.predict(X[:12].reshape(1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-985614f1d827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "X[[1,2,3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.1001001 ,   0.2002002 ,   0.3003003 ,\n",
       "         0.4004004 ,   0.5005005 ,   0.6006006 ,   0.7007007 ,\n",
       "         0.8008008 ,   0.9009009 ,   1.001001  ,   1.1011011 ,\n",
       "         1.2012012 ,   1.3013013 ,   1.4014014 ,   1.5015015 ,\n",
       "         1.6016016 ,   1.7017017 ,   1.8018018 ,   1.9019019 ,\n",
       "         2.002002  ,   2.1021021 ,   2.2022022 ,   2.3023023 ,\n",
       "         2.4024024 ,   2.5025025 ,   2.6026026 ,   2.7027027 ,\n",
       "         2.8028028 ,   2.9029029 ,   3.003003  ,   3.1031031 ,\n",
       "         3.2032032 ,   3.3033033 ,   3.4034034 ,   3.5035035 ,\n",
       "         3.6036036 ,   3.7037037 ,   3.8038038 ,   3.9039039 ,\n",
       "         4.004004  ,   4.1041041 ,   4.2042042 ,   4.3043043 ,\n",
       "         4.4044044 ,   4.5045045 ,   4.6046046 ,   4.7047047 ,\n",
       "         4.8048048 ,   4.9049049 ,   5.00500501,   5.10510511,\n",
       "         5.20520521,   5.30530531,   5.40540541,   5.50550551,\n",
       "         5.60560561,   5.70570571,   5.80580581,   5.90590591,\n",
       "         6.00600601,   6.10610611,   6.20620621,   6.30630631,\n",
       "         6.40640641,   6.50650651,   6.60660661,   6.70670671,\n",
       "         6.80680681,   6.90690691,   7.00700701,   7.10710711,\n",
       "         7.20720721,   7.30730731,   7.40740741,   7.50750751,\n",
       "         7.60760761,   7.70770771,   7.80780781,   7.90790791,\n",
       "         8.00800801,   8.10810811,   8.20820821,   8.30830831,\n",
       "         8.40840841,   8.50850851,   8.60860861,   8.70870871,\n",
       "         8.80880881,   8.90890891,   9.00900901,   9.10910911,\n",
       "         9.20920921,   9.30930931,   9.40940941,   9.50950951,\n",
       "         9.60960961,   9.70970971,   9.80980981,   9.90990991,\n",
       "        10.01001001,  10.11011011,  10.21021021,  10.31031031,\n",
       "        10.41041041,  10.51051051,  10.61061061,  10.71071071,\n",
       "        10.81081081,  10.91091091,  11.01101101,  11.11111111,\n",
       "        11.21121121,  11.31131131,  11.41141141,  11.51151151,\n",
       "        11.61161161,  11.71171171,  11.81181181,  11.91191191,\n",
       "        12.01201201,  12.11211211,  12.21221221,  12.31231231,\n",
       "        12.41241241,  12.51251251,  12.61261261,  12.71271271,\n",
       "        12.81281281,  12.91291291,  13.01301301,  13.11311311,\n",
       "        13.21321321,  13.31331331,  13.41341341,  13.51351351,\n",
       "        13.61361361,  13.71371371,  13.81381381,  13.91391391,\n",
       "        14.01401401,  14.11411411,  14.21421421,  14.31431431,\n",
       "        14.41441441,  14.51451451,  14.61461461,  14.71471471,\n",
       "        14.81481481,  14.91491491,  15.01501502,  15.11511512,\n",
       "        15.21521522,  15.31531532,  15.41541542,  15.51551552,\n",
       "        15.61561562,  15.71571572,  15.81581582,  15.91591592,\n",
       "        16.01601602,  16.11611612,  16.21621622,  16.31631632,\n",
       "        16.41641642,  16.51651652,  16.61661662,  16.71671672,\n",
       "        16.81681682,  16.91691692,  17.01701702,  17.11711712,\n",
       "        17.21721722,  17.31731732,  17.41741742,  17.51751752,\n",
       "        17.61761762,  17.71771772,  17.81781782,  17.91791792,\n",
       "        18.01801802,  18.11811812,  18.21821822,  18.31831832,\n",
       "        18.41841842,  18.51851852,  18.61861862,  18.71871872,\n",
       "        18.81881882,  18.91891892,  19.01901902,  19.11911912,\n",
       "        19.21921922,  19.31931932,  19.41941942,  19.51951952,\n",
       "        19.61961962,  19.71971972,  19.81981982,  19.91991992,\n",
       "        20.02002002,  20.12012012,  20.22022022,  20.32032032,\n",
       "        20.42042042,  20.52052052,  20.62062062,  20.72072072,\n",
       "        20.82082082,  20.92092092,  21.02102102,  21.12112112,\n",
       "        21.22122122,  21.32132132,  21.42142142,  21.52152152,\n",
       "        21.62162162,  21.72172172,  21.82182182,  21.92192192,\n",
       "        22.02202202,  22.12212212,  22.22222222,  22.32232232,\n",
       "        22.42242242,  22.52252252,  22.62262262,  22.72272272,\n",
       "        22.82282282,  22.92292292,  23.02302302,  23.12312312,\n",
       "        23.22322322,  23.32332332,  23.42342342,  23.52352352,\n",
       "        23.62362362,  23.72372372,  23.82382382,  23.92392392,\n",
       "        24.02402402,  24.12412412,  24.22422422,  24.32432432,\n",
       "        24.42442442,  24.52452452,  24.62462462,  24.72472472,\n",
       "        24.82482482,  24.92492492,  25.02502503,  25.12512513,\n",
       "        25.22522523,  25.32532533,  25.42542543,  25.52552553,\n",
       "        25.62562563,  25.72572573,  25.82582583,  25.92592593,\n",
       "        26.02602603,  26.12612613,  26.22622623,  26.32632633,\n",
       "        26.42642643,  26.52652653,  26.62662663,  26.72672673,\n",
       "        26.82682683,  26.92692693,  27.02702703,  27.12712713,\n",
       "        27.22722723,  27.32732733,  27.42742743,  27.52752753,\n",
       "        27.62762763,  27.72772773,  27.82782783,  27.92792793,\n",
       "        28.02802803,  28.12812813,  28.22822823,  28.32832833,\n",
       "        28.42842843,  28.52852853,  28.62862863,  28.72872873,\n",
       "        28.82882883,  28.92892893,  29.02902903,  29.12912913,\n",
       "        29.22922923,  29.32932933,  29.42942943,  29.52952953,\n",
       "        29.62962963,  29.72972973,  29.82982983,  29.92992993,\n",
       "        30.03003003,  30.13013013,  30.23023023,  30.33033033,\n",
       "        30.43043043,  30.53053053,  30.63063063,  30.73073073,\n",
       "        30.83083083,  30.93093093,  31.03103103,  31.13113113,\n",
       "        31.23123123,  31.33133133,  31.43143143,  31.53153153,\n",
       "        31.63163163,  31.73173173,  31.83183183,  31.93193193,\n",
       "        32.03203203,  32.13213213,  32.23223223,  32.33233233,\n",
       "        32.43243243,  32.53253253,  32.63263263,  32.73273273,\n",
       "        32.83283283,  32.93293293,  33.03303303,  33.13313313,\n",
       "        33.23323323,  33.33333333,  33.43343343,  33.53353353,\n",
       "        33.63363363,  33.73373373,  33.83383383,  33.93393393,\n",
       "        34.03403403,  34.13413413,  34.23423423,  34.33433433,\n",
       "        34.43443443,  34.53453453,  34.63463463,  34.73473473,\n",
       "        34.83483483,  34.93493493,  35.03503504,  35.13513514,\n",
       "        35.23523524,  35.33533534,  35.43543544,  35.53553554,\n",
       "        35.63563564,  35.73573574,  35.83583584,  35.93593594,\n",
       "        36.03603604,  36.13613614,  36.23623624,  36.33633634,\n",
       "        36.43643644,  36.53653654,  36.63663664,  36.73673674,\n",
       "        36.83683684,  36.93693694,  37.03703704,  37.13713714,\n",
       "        37.23723724,  37.33733734,  37.43743744,  37.53753754,\n",
       "        37.63763764,  37.73773774,  37.83783784,  37.93793794,\n",
       "        38.03803804,  38.13813814,  38.23823824,  38.33833834,\n",
       "        38.43843844,  38.53853854,  38.63863864,  38.73873874,\n",
       "        38.83883884,  38.93893894,  39.03903904,  39.13913914,\n",
       "        39.23923924,  39.33933934,  39.43943944,  39.53953954,\n",
       "        39.63963964,  39.73973974,  39.83983984,  39.93993994,\n",
       "        40.04004004,  40.14014014,  40.24024024,  40.34034034,\n",
       "        40.44044044,  40.54054054,  40.64064064,  40.74074074,\n",
       "        40.84084084,  40.94094094,  41.04104104,  41.14114114,\n",
       "        41.24124124,  41.34134134,  41.44144144,  41.54154154,\n",
       "        41.64164164,  41.74174174,  41.84184184,  41.94194194,\n",
       "        42.04204204,  42.14214214,  42.24224224,  42.34234234,\n",
       "        42.44244244,  42.54254254,  42.64264264,  42.74274274,\n",
       "        42.84284284,  42.94294294,  43.04304304,  43.14314314,\n",
       "        43.24324324,  43.34334334,  43.44344344,  43.54354354,\n",
       "        43.64364364,  43.74374374,  43.84384384,  43.94394394,\n",
       "        44.04404404,  44.14414414,  44.24424424,  44.34434434,\n",
       "        44.44444444,  44.54454454,  44.64464464,  44.74474474,\n",
       "        44.84484484,  44.94494494,  45.04504505,  45.14514515,\n",
       "        45.24524525,  45.34534535,  45.44544545,  45.54554555,\n",
       "        45.64564565,  45.74574575,  45.84584585,  45.94594595,\n",
       "        46.04604605,  46.14614615,  46.24624625,  46.34634635,\n",
       "        46.44644645,  46.54654655,  46.64664665,  46.74674675,\n",
       "        46.84684685,  46.94694695,  47.04704705,  47.14714715,\n",
       "        47.24724725,  47.34734735,  47.44744745,  47.54754755,\n",
       "        47.64764765,  47.74774775,  47.84784785,  47.94794795,\n",
       "        48.04804805,  48.14814815,  48.24824825,  48.34834835,\n",
       "        48.44844845,  48.54854855,  48.64864865,  48.74874875,\n",
       "        48.84884885,  48.94894895,  49.04904905,  49.14914915,\n",
       "        49.24924925,  49.34934935,  49.44944945,  49.54954955,\n",
       "        49.64964965,  49.74974975,  49.84984985,  49.94994995,\n",
       "        50.05005005,  50.15015015,  50.25025025,  50.35035035,\n",
       "        50.45045045,  50.55055055,  50.65065065,  50.75075075,\n",
       "        50.85085085,  50.95095095,  51.05105105,  51.15115115,\n",
       "        51.25125125,  51.35135135,  51.45145145,  51.55155155,\n",
       "        51.65165165,  51.75175175,  51.85185185,  51.95195195,\n",
       "        52.05205205,  52.15215215,  52.25225225,  52.35235235,\n",
       "        52.45245245,  52.55255255,  52.65265265,  52.75275275,\n",
       "        52.85285285,  52.95295295,  53.05305305,  53.15315315,\n",
       "        53.25325325,  53.35335335,  53.45345345,  53.55355355,\n",
       "        53.65365365,  53.75375375,  53.85385385,  53.95395395,\n",
       "        54.05405405,  54.15415415,  54.25425425,  54.35435435,\n",
       "        54.45445445,  54.55455455,  54.65465465,  54.75475475,\n",
       "        54.85485485,  54.95495495,  55.05505506,  55.15515516,\n",
       "        55.25525526,  55.35535536,  55.45545546,  55.55555556,\n",
       "        55.65565566,  55.75575576,  55.85585586,  55.95595596,\n",
       "        56.05605606,  56.15615616,  56.25625626,  56.35635636,\n",
       "        56.45645646,  56.55655656,  56.65665666,  56.75675676,\n",
       "        56.85685686,  56.95695696,  57.05705706,  57.15715716,\n",
       "        57.25725726,  57.35735736,  57.45745746,  57.55755756,\n",
       "        57.65765766,  57.75775776,  57.85785786,  57.95795796,\n",
       "        58.05805806,  58.15815816,  58.25825826,  58.35835836,\n",
       "        58.45845846,  58.55855856,  58.65865866,  58.75875876,\n",
       "        58.85885886,  58.95895896,  59.05905906,  59.15915916,\n",
       "        59.25925926,  59.35935936,  59.45945946,  59.55955956,\n",
       "        59.65965966,  59.75975976,  59.85985986,  59.95995996,\n",
       "        60.06006006,  60.16016016,  60.26026026,  60.36036036,\n",
       "        60.46046046,  60.56056056,  60.66066066,  60.76076076,\n",
       "        60.86086086,  60.96096096,  61.06106106,  61.16116116,\n",
       "        61.26126126,  61.36136136,  61.46146146,  61.56156156,\n",
       "        61.66166166,  61.76176176,  61.86186186,  61.96196196,\n",
       "        62.06206206,  62.16216216,  62.26226226,  62.36236236,\n",
       "        62.46246246,  62.56256256,  62.66266266,  62.76276276,\n",
       "        62.86286286,  62.96296296,  63.06306306,  63.16316316,\n",
       "        63.26326326,  63.36336336,  63.46346346,  63.56356356,\n",
       "        63.66366366,  63.76376376,  63.86386386,  63.96396396,\n",
       "        64.06406406,  64.16416416,  64.26426426,  64.36436436,\n",
       "        64.46446446,  64.56456456,  64.66466466,  64.76476476,\n",
       "        64.86486486,  64.96496496,  65.06506507,  65.16516517,\n",
       "        65.26526527,  65.36536537,  65.46546547,  65.56556557,\n",
       "        65.66566567,  65.76576577,  65.86586587,  65.96596597,\n",
       "        66.06606607,  66.16616617,  66.26626627,  66.36636637,\n",
       "        66.46646647,  66.56656657,  66.66666667,  66.76676677,\n",
       "        66.86686687,  66.96696697,  67.06706707,  67.16716717,\n",
       "        67.26726727,  67.36736737,  67.46746747,  67.56756757,\n",
       "        67.66766767,  67.76776777,  67.86786787,  67.96796797,\n",
       "        68.06806807,  68.16816817,  68.26826827,  68.36836837,\n",
       "        68.46846847,  68.56856857,  68.66866867,  68.76876877,\n",
       "        68.86886887,  68.96896897,  69.06906907,  69.16916917,\n",
       "        69.26926927,  69.36936937,  69.46946947,  69.56956957,\n",
       "        69.66966967,  69.76976977,  69.86986987,  69.96996997,\n",
       "        70.07007007,  70.17017017,  70.27027027,  70.37037037,\n",
       "        70.47047047,  70.57057057,  70.67067067,  70.77077077,\n",
       "        70.87087087,  70.97097097,  71.07107107,  71.17117117,\n",
       "        71.27127127,  71.37137137,  71.47147147,  71.57157157,\n",
       "        71.67167167,  71.77177177,  71.87187187,  71.97197197,\n",
       "        72.07207207,  72.17217217,  72.27227227,  72.37237237,\n",
       "        72.47247247,  72.57257257,  72.67267267,  72.77277277,\n",
       "        72.87287287,  72.97297297,  73.07307307,  73.17317317,\n",
       "        73.27327327,  73.37337337,  73.47347347,  73.57357357,\n",
       "        73.67367367,  73.77377377,  73.87387387,  73.97397397,\n",
       "        74.07407407,  74.17417417,  74.27427427,  74.37437437,\n",
       "        74.47447447,  74.57457457,  74.67467467,  74.77477477,\n",
       "        74.87487487,  74.97497497,  75.07507508,  75.17517518,\n",
       "        75.27527528,  75.37537538,  75.47547548,  75.57557558,\n",
       "        75.67567568,  75.77577578,  75.87587588,  75.97597598,\n",
       "        76.07607608,  76.17617618,  76.27627628,  76.37637638,\n",
       "        76.47647648,  76.57657658,  76.67667668,  76.77677678,\n",
       "        76.87687688,  76.97697698,  77.07707708,  77.17717718,\n",
       "        77.27727728,  77.37737738,  77.47747748,  77.57757758,\n",
       "        77.67767768,  77.77777778,  77.87787788,  77.97797798,\n",
       "        78.07807808,  78.17817818,  78.27827828,  78.37837838,\n",
       "        78.47847848,  78.57857858,  78.67867868,  78.77877878,\n",
       "        78.87887888,  78.97897898,  79.07907908,  79.17917918,\n",
       "        79.27927928,  79.37937938,  79.47947948,  79.57957958,\n",
       "        79.67967968,  79.77977978,  79.87987988,  79.97997998,\n",
       "        80.08008008,  80.18018018,  80.28028028,  80.38038038,\n",
       "        80.48048048,  80.58058058,  80.68068068,  80.78078078,\n",
       "        80.88088088,  80.98098098,  81.08108108,  81.18118118,\n",
       "        81.28128128,  81.38138138,  81.48148148,  81.58158158,\n",
       "        81.68168168,  81.78178178,  81.88188188,  81.98198198,\n",
       "        82.08208208,  82.18218218,  82.28228228,  82.38238238,\n",
       "        82.48248248,  82.58258258,  82.68268268,  82.78278278,\n",
       "        82.88288288,  82.98298298,  83.08308308,  83.18318318,\n",
       "        83.28328328,  83.38338338,  83.48348348,  83.58358358,\n",
       "        83.68368368,  83.78378378,  83.88388388,  83.98398398,\n",
       "        84.08408408,  84.18418418,  84.28428428,  84.38438438,\n",
       "        84.48448448,  84.58458458,  84.68468468,  84.78478478,\n",
       "        84.88488488,  84.98498498,  85.08508509,  85.18518519,\n",
       "        85.28528529,  85.38538539,  85.48548549,  85.58558559,\n",
       "        85.68568569,  85.78578579,  85.88588589,  85.98598599,\n",
       "        86.08608609,  86.18618619,  86.28628629,  86.38638639,\n",
       "        86.48648649,  86.58658659,  86.68668669,  86.78678679,\n",
       "        86.88688689,  86.98698699,  87.08708709,  87.18718719,\n",
       "        87.28728729,  87.38738739,  87.48748749,  87.58758759,\n",
       "        87.68768769,  87.78778779,  87.88788789,  87.98798799,\n",
       "        88.08808809,  88.18818819,  88.28828829,  88.38838839,\n",
       "        88.48848849,  88.58858859,  88.68868869,  88.78878879,\n",
       "        88.88888889,  88.98898899,  89.08908909,  89.18918919,\n",
       "        89.28928929,  89.38938939,  89.48948949,  89.58958959,\n",
       "        89.68968969,  89.78978979,  89.88988989,  89.98998999,\n",
       "        90.09009009,  90.19019019,  90.29029029,  90.39039039,\n",
       "        90.49049049,  90.59059059,  90.69069069,  90.79079079,\n",
       "        90.89089089,  90.99099099,  91.09109109,  91.19119119,\n",
       "        91.29129129,  91.39139139,  91.49149149,  91.59159159,\n",
       "        91.69169169,  91.79179179,  91.89189189,  91.99199199,\n",
       "        92.09209209,  92.19219219,  92.29229229,  92.39239239,\n",
       "        92.49249249,  92.59259259,  92.69269269,  92.79279279,\n",
       "        92.89289289,  92.99299299,  93.09309309,  93.19319319,\n",
       "        93.29329329,  93.39339339,  93.49349349,  93.59359359,\n",
       "        93.69369369,  93.79379379,  93.89389389,  93.99399399,\n",
       "        94.09409409,  94.19419419,  94.29429429,  94.39439439,\n",
       "        94.49449449,  94.59459459,  94.69469469,  94.79479479,\n",
       "        94.89489489,  94.99499499,  95.0950951 ,  95.1951952 ,\n",
       "        95.2952953 ,  95.3953954 ,  95.4954955 ,  95.5955956 ,\n",
       "        95.6956957 ,  95.7957958 ,  95.8958959 ,  95.995996  ,\n",
       "        96.0960961 ,  96.1961962 ,  96.2962963 ,  96.3963964 ,\n",
       "        96.4964965 ,  96.5965966 ,  96.6966967 ,  96.7967968 ,\n",
       "        96.8968969 ,  96.996997  ,  97.0970971 ,  97.1971972 ,\n",
       "        97.2972973 ,  97.3973974 ,  97.4974975 ,  97.5975976 ,\n",
       "        97.6976977 ,  97.7977978 ,  97.8978979 ,  97.997998  ,\n",
       "        98.0980981 ,  98.1981982 ,  98.2982983 ,  98.3983984 ,\n",
       "        98.4984985 ,  98.5985986 ,  98.6986987 ,  98.7987988 ,\n",
       "        98.8988989 ,  98.998999  ,  99.0990991 ,  99.1991992 ,\n",
       "        99.2992993 ,  99.3993994 ,  99.4994995 ,  99.5995996 ,\n",
       "        99.6996997 ,  99.7997998 ,  99.8998999 , 100.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
