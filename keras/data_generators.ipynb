{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Keras Generator\n",
    "This notebook outlines how to build custom Keras generators. These are used to feed in more complex data into models with potentially complex processing, such as image augmentation. It also allows for multiple datasets to be fed into the model for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow\n",
    "\n",
    "# Load entire dataset\n",
    "X = np.linspace(0,100, 10000)\n",
    "y = np.sin(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Input/Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X,y, batch_size = 64):\n",
    "    \n",
    "    \"\"\"\n",
    "    Overview\n",
    "    --------\n",
    "    Simple Keras data generating function.\n",
    "    \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    X (numpy.ndarray): NumPy array of training data, with number\n",
    "        of samples in the first dimension.\n",
    "    y (numpy.ndarray): NumPy array of target data, with number\n",
    "        of samples in the first dimension.\n",
    "    batch_size (int, optional): Batch size.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Subset of X and y of size batch_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_length = len(X)\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_idx = np.random.randint(0, X_length, (batch_size))\n",
    "        \n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        batch_x = np.array(X[batch_idx])\n",
    "        batch_y = np.array(y[batch_idx])\n",
    "        \n",
    "        yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design model\n",
    "model = Sequential()\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 18.6917\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.5521\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5546\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5482\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5512\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 2s 12ms/step - loss: 0.5452\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.5406\n",
      "Epoch 8/10\n",
      " 87/156 [===============>..............] - ETA: 0s - loss: 0.5645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d15a49a3b1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m           update_ops.extend(\n\u001b[1;32m    484\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 485\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/rmsprop.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    185\u001b[0m       var_t = var - coefficients[\"lr_t\"] * grad / (\n\u001b[1;32m    186\u001b[0m           math_ops.sqrt(denom_t) + coefficients[\"epsilon\"])\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resource_apply_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         validate_shape=validate_shape)\n\u001b[0;32m--> 228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    816\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[1;32m    817\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     return _UnreadVariable(\n\u001b[1;32m    789\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m   \u001b[0;34m\"\"\"Records that `variable` was accessed for the tape and FuncGraph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"watch_variable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5875\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m   \"\"\"\n\u001b[0;32m-> 5877\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5456\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5457\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5459\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5271\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(image_generator(X, y, 32), steps_per_epoch = len(X)//64, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 331.6825\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 4s 24ms/step - loss: 67.1280\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 8.0176\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.7204\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.5353\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.5369\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 4s 28ms/step - loss: 0.5189\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 4s 25ms/step - loss: 0.5062\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 4s 24ms/step - loss: 0.5032\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 4s 23ms/step - loss: 0.5097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f439c2d5470>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs_main = Input(shape=(1,))\n",
    "inputs_aux = Input(shape=(1,))\n",
    "\n",
    "output_1_main = Dense(1, activation='relu')(inputs_main)\n",
    "output_2_main = Dense(1, activation='relu')(output_1_main)\n",
    "\n",
    "output_1_aux = Dense(1, activation='relu')(inputs_aux)\n",
    "output_2_aux = Dense(1, activation='relu')(output_1_aux)\n",
    "\n",
    "added = tensorflow.keras.layers.Add()([output_2_main, output_2_aux])\n",
    "\n",
    "predictions = Dense(1)(added)\n",
    "\n",
    "model = Model(inputs=[inputs_main, inputs_aux], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit_generator(multi_input_data_generator(X, y, 32), steps_per_epoch = len(X)//64, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the data is in the format (time step, feature)\n",
    "\n",
    "the data will be in the format (sample, time_step, feature) after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_series_generator:\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates batches of time series data suitable for Keras.\n",
    "    \n",
    "    Keras requires time series data to be fed in with the format \n",
    "    (batch_size, time_lags, features). This generator automatically\n",
    "    reshapes tabular data. It also adds sinusoidal waves to give the\n",
    "    neural net some concepts of where in the period we are located,\n",
    "    as neural networks do not model periodicity very well.\n",
    "    \n",
    "    Handles multivariable inputs and outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, lags, horizon, batch_size, period):\n",
    "        \n",
    "        \"Initialise generator class.\"\n",
    "        \n",
    "        self.lags = lags\n",
    "        self.horizon = horizon\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.period = period\n",
    "        \n",
    "        self.sin_period, self.cos_period = self.calc_sinusoidal_time(self.period)\n",
    "        \n",
    "    def calc_sinusoidal_time(self, period):\n",
    "        \n",
    "        \"\"\"\n",
    "        Encodes periodicity of the data into sinusoidal features.\n",
    "        \n",
    "        \n",
    "        Inputs\n",
    "        ------\n",
    "        period (int): Periodicity of the data.\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A pair of sine and cosine wave with periodicity equal to\n",
    "            the passed value of period.\n",
    "        \"\"\"\n",
    "        \n",
    "        t = np.arange(len(self.X)) % period\n",
    "        wave_arg = 2*np.pi*t/np.max(period)\n",
    "        \n",
    "        return np.sin(wave_arg), np.cos(wave_arg)\n",
    "    \n",
    "    def flow(self, X, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generates a list of input data and target data.\n",
    "        \n",
    "        The input data list contains the reshaped time series data\n",
    "        and another dataset containing sinusoidal features.\n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "        \n",
    "            input_batch_1 = []\n",
    "            sinusoidal_batch = []\n",
    "            targets_batch = []\n",
    "    \n",
    "            for i in range(self.batch_size):\n",
    "                # Need to start indexing from lags\n",
    "                data_idx = np.random.randint(self.lags, len(X) - self.horizon)\n",
    "    \n",
    "                data_lags = X[data_idx - lags: data_idx]\n",
    "                input_batch_1.append(data_lags)\n",
    "            \n",
    "                targets = y[data_idx:data_idx + self.horizon]\n",
    "                targets_batch.append(targets) \n",
    "        \n",
    "                sinusoidal_feature = np.concatenate([self.sin_period[data_idx - self.lags: data_idx], \n",
    "                                                 self.cos_period[data_idx - self.lags: data_idx]])\n",
    "            \n",
    "                sinusoidal_batch.append(sinusoidal_feature)\n",
    "            \n",
    "            input_batch_1 = np.reshape(input_batch_1, (self.batch_size, self.lags, -1))\n",
    "            sinusoidal_batch = np.reshape(sinusoidal_batch, (self.batch_size, self.lags * 2, -1))\n",
    "            targets_batch = np.reshape(targets_batch, (self.batch_size, -1))\n",
    "    \n",
    "            yield [input_batch_1, sinusoidal_batch], targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "lags = 12\n",
    "horizon = 8\n",
    "batch_size =  32\n",
    "period = int(2*np.pi*100)\n",
    "features = 1\n",
    "\n",
    "# Generate data\n",
    "\n",
    "X = np.linspace(0,10,1000).reshape((1000, -1))\n",
    "print(np.shape(X))\n",
    "y = np.sin(X) + np.random.normal(0,0.01, (1000,1))\n",
    "print(np.shape(y))\n",
    "y = y.reshape((1000,1))\n",
    "\n",
    "data_gen = time_series_generator(X, y, lags, horizon, batch_size, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.2752\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0369\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0205\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0129\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0104\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 0.0081\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0059\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0044\n",
      "Epoch 9/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0040\n",
      "Epoch 10/15\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.0031\n",
      "Epoch 11/15\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0028\n",
      "Epoch 12/15\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0023\n",
      "Epoch 13/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0022\n",
      "Epoch 14/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0017\n",
      "Epoch 15/15\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f424fdb32b0>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "units = 64\n",
    "\n",
    "# This returns a tensor\n",
    "inputs_main = Input(shape=(lags,features))\n",
    "inputs_aux = Input(shape=(lags * 2, 1))\n",
    "\n",
    "output_1_main = Dense(units, activation='relu')(inputs_main)\n",
    "output_2_main = Dense(units, activation='relu')(output_1_main)\n",
    "\n",
    "output_1_aux = Dense(units, activation='relu')(inputs_aux)\n",
    "output_2_aux = Dense(units, activation='relu')(output_1_aux)\n",
    "\n",
    "concat = tensorflow.keras.layers.Concatenate(axis=1)([output_2_main, output_2_aux])\n",
    "\n",
    "flatten = Flatten()(concat)\n",
    "dense1 = Dense(units, activation='relu')(flatten)\n",
    "\n",
    "predictions = Dense(horizon, activation = 'tanh')(dense1)\n",
    "\n",
    "model = Model(inputs=[inputs_main, inputs_aux], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit_generator(data_gen.flow(X, y), steps_per_epoch = len(X)//64, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y.reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_generator(data_gen.flow(X, y), steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0.        ],\n        [0.01001001],\n        [0.02002002],\n        [0.03003003],\n        [0.04004004],\n        [0.05005005],\n        [0.06006006],\n        [0.07007007],\n        [0.08008008],\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-620b435ee574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/virtual_environments/standard_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    529\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0.        ],\n        [0.01001001],\n        [0.02002002],\n        [0.03003003],\n        [0.04004004],\n        [0.05005005],\n        [0.06006006],\n        [0.07007007],\n        [0.08008008],\n ..."
     ]
    }
   ],
   "source": [
    "model.predict(X[:12].reshape(1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
